# Guidelines on the use of Generative Artificial Intelligence (AI) in CESSDA Main Office

## Description

CESSDA MO has prepared some general guidelines for the safe and responsible use of Generative AI systems, such as Gemini and ChatGPT. Should you use or intend to use such systems, please check these instructions. 


## General guidelines

Generative Artificial Intelligence (AI), such as Gemini and ChatGPT, has garnered significant attention worldwide. While this technology can contribute to solving many societal challenges and reshape industries, its development remains at an early stage. The European Union recognises the transformative capabilities of AI, and through regulatory frameworks like the EU AI Act, seeks to ensure that such systems are deployed safely, ethically, and transparently, in alignment with European values and fundamental rights.

Gemini and ChatGPT are examples of Generative AI systems that are designed to engage in human-like conversational interactions through natural language processing (NLP). These systems are developed and trained on extensive datasets, which are often scraped from public resources, to generate coherent and contextually relevant responses.

As CESSDA and its Service Providers operate in the EU, our practice must adhere to the General Data Protection Regulation (GDPR). If you decide to use or test Generative AI systems, please be mindful of the following guidelines:

- **Do not share confidential information**
    - *The information you share with Gemini or ChatGPT will be processed and reused by their respective providers, Google or Open AI, to improve the system’s performance.* This data may also be accessed by authorised personnel, such as Google or OpenAI staff, or potentially shared with other users of the system. 
    - *The security of the data shared with Generative AI cannot be fully guaranteed.* There remains a risk that information could be stolen or damaged. Under the EU AI Act, high-risk AI systems must implement robust security measures to mitigate such risks, but users should remain cautious about sharing sensitive or personal information.

- **Always check and verify the results proposed by Generative AI**
    - The training datasets for Generative AI are not real-time. For example, as of writing, the dataset used to train ChatGPT is from 2021 and is not up to date. Therefore, results may be outdated, inaccurate, or incomplete.
    - Generative AI can present false information in a [highly convincing manner](https://arstechnica.com/tech-policy/2023/06/lawyers-have-real-bad-day-in-court-after-citing-fake-cases-made-up-by-chatgpt/). The EU AI Act highlights the importance of risk management to prevent the dissemination of misleading or harmful information.
    - There is currently a lack of transparency regarding the sources of information used by the algorithm to generate responses. Repurposing Germini or ChatGPT results may infringe intellectual property rights.

CESSDA is closely monitoring product developments and will update these guidelines as technology and regulatory frameworks advance.


## Further Resources

As CESSDA operates under the framework of the European Research Infrastructure Consortium (ERIC) adopted by the European Commission, please find below some additional resources provided by EU institutions:

- The [European AI Act](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai) (Regulation (EU) 2024/1689) (European Commission 2024): The EU AI Act is the world’s first comprehensive AI law.
- [Artificial Intelligence Q&As](https://ec.europa.eu/commission/presscorner/detail/en/qanda_21_1683) (European Commission 2024): Some common questions and answers on the EU AI Act and the risk-based approach taken across all EU Member States.
- The [European AI Office](https://digital-strategy.ec.europa.eu/en/policies/ai-office) (European Commission 2024): The European AI Office is the centre of AI expertise across the EU. It plays a key role in implementing the AI Act - especially for general-purpose AI - fostering the development and use of trustworthy AI, and international cooperation.
- [European approach to AI](https://digital-strategy.ec.europa.eu/en/policies/european-approach-artificial-intelligence) (European Commission 2024): The EU’s approach to artificial intelligence centres on excellence and trust, aiming to boost research and industrial capacity while ensuring safety and fundamental rights.
- [EU AI Act: first regulation on artificial intelligence](https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence) (European Parliament 2024): A short article on the AI act, transparency requirements, supporting innovation, and next steps on the EU’s digital measures.
- [EU’s Coordinated Plan on AI](https://digital-strategy.ec.europa.eu/en/policies/plan-ai) (European Commission 2024): This webpage explains the Coordinated Plan of 2021 and expands on the 2024 “Communication on boosting startups and innovation in trustworthy AI”. 
- [Coordinated Plan on AI 2021 Review](https://digital-strategy.ec.europa.eu/en/library/coordinated-plan-artificial-intelligence-2021-review) (European Commission 2021): This is the latest published version of the plan which aligns with the Commission’s digital and green priorities and Europe’s response to the COVID-19 pandemic.
- [General Data Protection Regulation (GDPR)](https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:32016R0679) (European Union 2016): This is the official PDF of the EU Regulation 2016/679 (OJ L 119, 04.05.2016).
- [OpenAI privacy policy](https://openai.com/en-GB/policies/privacy-policy/)
- [OpenAI Data Controls](https://help.openai.com/en/articles/7730893-data-controls-faq)
